{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d7cafe-6fca-4a70-bd66-b5819383b1fa",
   "metadata": {},
   "source": [
    "# Predictive modeling for heart disease classification using Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee856a-0a9c-40c8-8a17-4e58d6cc65db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2bdf3-2a19-4fcf-baf3-76f0a5114769",
   "metadata": {},
   "source": [
    "## Project Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d549e4-d189-429a-bc8c-ee1991c238ac",
   "metadata": {},
   "source": [
    "**Authors**: \n",
    "- Vladyslav Lysenko\n",
    "- Parmida Mashadi Assadollahi\n",
    "- Sankruththian Senathirajah\n",
    "  \n",
    "**Course**: SCS 3251-071 Statistics for Data Science  \n",
    "**Instructor**: Sergiy Nokhrin  \n",
    "**Institution**: University of Toronto School of Continuing Studies  \n",
    "**Submission Date**: November 2025  \n",
    "**Purpose**:  \n",
    "\n",
    "\n",
    "![University Logo](https://learn.utoronto.ca/themes/custom/de_theme/logo.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f9c8d-56d8-4529-b307-0d5a5c7f08bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f42c742-07a2-4447-88fe-24f53fe83bea",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa687e-d69e-4c26-b9ff-aeb13eb018c0",
   "metadata": {},
   "source": [
    "1. [Project Information](#Project-Information)\n",
    "2. [Introduction](#Introduction)\n",
    "3. [Material and Methods](#Material-and-Methods)\n",
    "4. [Exploratory Data Analysis (EDA)](#Exploratory-Data-Analysis)\n",
    "    - 4.1 [Univariate Analysis](#Univariate-Analysis)\n",
    "    - 4.2 [Multivariate Analysis](#Multivariate-Analysis)\n",
    "5. [Hypothesis Testing](#Hypothesis-Testing)\n",
    "6. [Modeling](#Modeling)\n",
    "7. [Evaluation](#Evaluation)\n",
    "8. [Key Findings](#Key-Findings)\n",
    "9. [Limitations](#Limitations)\n",
    "10. [Future Work](#Future-Work)\n",
    "11. [Conclusions](#Conclusions)\n",
    "12. [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d57d2f-367d-44dc-849c-92ff26eddb12",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f93b8cb-7dac-4eca-9424-9e77a6f7546d",
   "metadata": {},
   "source": [
    "Cardiovascular disease (CVD) is one of the most known and deadly diseases in the world, taking millions of lives each year <sup>[[1]](#C.-References)</sup>. Early detection plays a critical role in improving outcomes, as timely intervention can significantly reduce the risk of severe complications or death. However, the diagnostic process is often complex, requiring multiple clinical tests, specialized expertise, and considerable time and resources.\n",
    "\n",
    "Machine learning (ML) offers a complementary approach to traditional diagnostics. By analyzing patterns in patient data, ML models can provide rapid, low-cost, and consistent assessments that support clinicians in identifying individuals at risk. While not a replacement for medical evaluation, ML can serve as an effective tool for preliminary screening and decision support, helping streamline the diagnostic workflow<sup>[[2]](#C.-References)</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6114cff-bdb0-4fac-8cd0-96e793999562",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9473e95-033f-4e79-b2f7-dce2e8f0777f",
   "metadata": {},
   "source": [
    "The objective of applying machine learning in our project is to explore whether simple statistical models can detect patterns associated with heart disease earlier or more reliably than manual inspection alone. By modeling how clinical features interact, we aim to produce a transparent risk-prediction tool that could support clinicians in screening and decision-making.\n",
    "\n",
    "In this project we aim to obtain an ML model that can predict heart disease using a probabilistic Gaussian Naive Bayes classifier. To accomplish that, we first perform exploratory data analysis to characterize the distribution of key variables and identify potential risk factors. We then preprocess the data (handling missing values, encoding categorical features, and scaling numerical variables where appropriate) and derive a binary outcome reflecting the presence or absence of heart disease. The model is trained and evaluated on separate train-test splits, and its performance is assessed using standard classification metrics (accuracy, precision, recall, F1-score, and ROC-AUC). Finally, we interpret the learned conditional distributions and feature effects to understand which clinical variables contribute most to predicted risk, and we discuss the potential usefulness and limitations of such a simple, interpretable model in a real clinical screening setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5a2c6-fe03-4b38-af70-3aef359d38fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Material and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5176cf-76c1-40f0-83b3-be86624e5714",
   "metadata": {},
   "source": [
    "This project focuses on applying a simple, interpretable machine learning approach to the problem of heart disease prediction by using the Gaussian Naive Bayes algorithm as the primary classifier. The method was chosen for its efficiency, transparency, and strong performance on smaller datasets, making it well suited for an initial evaluation of predictive potential in medical data. Basic preprocessing steps were carried out to ensure clean and consistent input, including encoding categorical variables, standardizing selected numerical features, and splitting the data into training and testing sets. The Cleveland dataset used in this study was obtained from the UC Irvine Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c53e6e-9a39-4a8b-ad55-acf861118861",
   "metadata": {},
   "source": [
    "### Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e6985-8b38-47f8-a7d2-ee8f2944a742",
   "metadata": {},
   "source": [
    "The Cleveland heart disease dataset is commonly used for heart disease prediction with supervised Machine Learning. The Cleveland dataset is obtained from the UC Irvine Machine Learning repository.\n",
    "\n",
    "The Cleveland dataset was collected for use in a study in the field of health research by the Cleveland Clinic Foundation in 1988. In the original of this dataset, 76 different features of 303 subjects were recorded. However, it is known that most researchers use only 14 of these features, including the target class feature. These features include age, gender, blood pressure, cholesterol, blood sugar, and many more health metrics. \n",
    "\n",
    "The original Cleveland dataset has five class labels. It has integer values ranging from zero (no presence) to four. The Cleveland dataset experiments have focused on just trying to discriminate between presence (Values 1, 2, 3, 4) and absence (Value 0). However, the number of samples for each class is not homogeneous (Values 0, 1, 2, 3, 4-samples 164, 55, 36, 35, 13). Researchers suggest that the five class features of this data set be reduced to two classes; 0 = no disease and 1 = disease. The target feature refers to the presence of heart disease in the subject. Table 1 shows the features included in the Cleveland heart disease dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e4444-eede-4ad4-9776-8caf4b724627",
   "metadata": {},
   "source": [
    "| Order | Feature   | Description                                                                                          | Feature Value Range                                                                                                                             |\n",
    "|-------|-----------|------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 1     | Age       | Age in years                                                                                         | 29 to 77                                                                                                                                        |\n",
    "| 2     | Sex       | Gender                                                                                               | 1 = male, 0 = female                                                                                                                            |\n",
    "| 3     | Cp        | Chest pain type                                                                                       | 0 = typical angina; 1 = atypical angina; 2 = non-anginal pain; 3 = asymptomatic                                                                 |\n",
    "| 4     | Trestbps  | Resting blood pressure (mm Hg on hospital admission)                                                  | 94 to 200                                                                                                                                       |\n",
    "| 5     | Chol      | Serum cholesterol (mg/dL)                                                                             | 126 to 564                                                                                                                                      |\n",
    "| 6     | Fbs       | Fasting blood sugar > 120 mg/dL                                                                       | 1 = true, 0 = false                                                                                                                             |\n",
    "| 7     | Restecg   | Resting electrocardiographic results                                                                  | 0 = normal; 1 = ST-T wave abnormality; 2 = left ventricular hypertrophy (Estes’ criteria)                                                       |\n",
    "| 8     | Thalach   | Maximum heart rate achieved                                                                           | 71 to 202                                                                                                                                       |\n",
    "| 9     | Exang     | Exercise-induced angina                                                                               | 1 = yes, 0 = no                                                                                                                                 |\n",
    "| 10    | Oldpeak   | ST depression induced by exercise relative to rest                                                    | 0 to 6.2                                                                                                                                        |\n",
    "| 11    | Slope     | Slope of the peak exercise ST segment                                                                 | 0 = upsloping; 1 = flat; 2 = downsloping                                                                                                        |\n",
    "| 12    | Ca        | Number of major vessels colored by fluoroscopy                                                        | 0 to 3                                                                                                                                          |\n",
    "| 13    | Thal      | Thallium heart rate test result                                                                       | 0 = normal; 1 = fixed defect; 2 = reversible defect                                                                                             |\n",
    "| 14    | Target    | Diagnosis of heart disease                                                                            | 0 = no disease; 1 = disease                                                                                                                     |\n",
    "\n",
    "\n",
    "<center><i>Table 1: List of features in the Cleveland heart disease dataset.</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9428663-73d5-412d-83c2-f4f1cf538c7b",
   "metadata": {},
   "source": [
    "In the original dataset, a total of 6 samples have null values; 4 samples in the “Ca (Number of Major Vessels)” feature and 2 samples in the “Thal (Thallium Heart Rate)” feature. Since null values are very few, these samples can be removed from the dataset. The dataset used in this study contains a total of 303 samples. A total of 137 samples belong to the disease (1), and 160 of these samples belong to the no disease (0) class. Histograms of all features in the Cleveland heart disease dataset are shown in [multivariate analysis](#Multivariate-Analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52290aec-1ec0-4876-80d3-d5412565249c",
   "metadata": {},
   "source": [
    "### Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4bd4aa-6006-4b04-a23c-7328951d76dc",
   "metadata": {},
   "source": [
    "- #### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91793afb-3fbf-4bb1-969b-2a272e968215",
   "metadata": {},
   "source": [
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable<sup>[[3]](#C.-References)</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210d898-4c3a-46e3-a940-70ed0af81a69",
   "metadata": {},
   "source": [
    "Naive conditional independece assumption: $$P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n) = P(x_i | y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af19b0-1450-415a-bedf-63f1af8564b3",
   "metadata": {},
   "source": [
    "Naive Bayes classification rule: \\begin{align}\\begin{aligned}P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)\\end{aligned}\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba9bdb-bf9f-434f-971b-e0f6ccbdb63b",
   "metadata": {},
   "source": [
    "The different naive Bayes classifiers differ mainly by the assumptions they make regarding the distribution of $P(x_i\\:|\\:y)$. In case of Gaussian Naive Bayes, we, as comes from the name, assume probability to be normaly distributed. The likelihood of the features is assumed to be Gaussian: $$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c5fa7-dbeb-4a55-b6e4-e44e0d7aae2f",
   "metadata": {},
   "source": [
    "**Strengths**:\n",
    "- Extremely fast to train\n",
    "- Works well even with small datasets\n",
    "- Easy to interpret (means and variances reveal feature influence)\n",
    "\n",
    "**Limitations**:\n",
    "- Independence assumption is rarely true\n",
    "- Probability outputs are often not well-calibrated\n",
    "- Performance may lag behind more flexible models\n",
    "\n",
    "Despite these limitations, Naïve Bayes often performs strongly for classification tasks, and it serves as a clear, interpretable baseline for health data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255fcf50-57d3-49e7-a8de-60e75c98f0d1",
   "metadata": {},
   "source": [
    "- #### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adce7b0-5bd5-4aca-b3fd-6fa3dcf98c06",
   "metadata": {},
   "source": [
    "Logistic regression is a classification algorithm that models the probability of a binary outcome<sup>[[4]](#C.-References)</sup>. Instead of predicting $y$ directly, it estimates: $$\\hat{p} = P(y=1 \\mid \\mathbf{x}) = \\sigma\\!\\left(\\beta_0 + \\sum_{i=1}^{n} \\beta_i x_i\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8ce4e5-e9e2-44f6-b837-f81ec5e10962",
   "metadata": {},
   "source": [
    "where $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ is the sigmoid function. The model parameters $\\beta$ are learned by maximizing the log-likelihood (or equivalently minimizing cross-entropy loss): $$L = -\\sum_{j=1}^{m} \\left[ y_j \\log(\\hat{p}_j) + (1 - y_j)\\log(1 - \\hat{p}_j) \\right]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53446734-8ed5-4c9b-b45e-584c181e0da7",
   "metadata": {},
   "source": [
    "In this project, logistic regression serves as a baseline classifier to compare against the main algorithm, Naive Bayes. Its simplicity and interpretability make it a standard reference for tasks like predicting heart disease presence in the Cleveland dataset, where outputs are binary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5e1aa-1583-44e1-8c57-c7615ef00dcf",
   "metadata": {},
   "source": [
    "Logistic regression performs reasonably because it captures nonlinear output behavior through the sigmoid but still relies on linear combinations of features. Thus, it may not fully model complex feature interactions. Comparing its accuracy with Naive Bayes helps demonstrate whether probabilistic modeling of feature distributions provides superior predictive performance for this medical dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd2395-ce64-4d53-9373-2e28c6fc36a6",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5bd05d-c4a3-48d3-bc2b-e424c736ba84",
   "metadata": {},
   "source": [
    "The dataset comprises 303 subjects and a set of clinical variables commonly associated with cardiovascular risk. The cohort is predominantly middle-aged to older and male. Resting systolic blood pressure and total cholesterol are moderately elevated on average (131.7 mmHg and 246.7 mg/dL, respectively), while maximum heart rate (thalach) and ST depression (oldpeak) show substantial variability, indicating heterogeneous cardiovascular fitness and ischemic burden. \n",
    "\n",
    "The outcome variable (target) spans 0 - 4 and is further recoded into a binary indicator distinguishing healthy from diseased subjects. In the following [univariate analysis](#Univariate-Analysis), we first inspect the overall distribution of this outcome, and then examine how disease prevalence varies across key risk factors, focusing on sex and age groups as illustrated in the subsequent plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc28a9e-793c-43bf-a116-3b71a17b8997",
   "metadata": {},
   "source": [
    "| Feature   | Count |   Mean    |    Std    | Min | 25%  | 50%  | 75%  | Max |\n",
    "|-----------|-------|-----------|-----------|-----|------|------|------|-----|\n",
    "| age       |   303 |   54.4389 |   9.03866 |  29 |   48 |   56 |   61 |  77 |\n",
    "| sex       |   303 |    0.6799 |   0.4673  |   0 |    0 |    1 |    1 |   1 |\n",
    "| cp        |   303 |    3.1584 |   0.9601  |   1 |    3 |    3 |    4 |   4 |\n",
    "| trestbps  |   303 |  131.6900 |  17.5997  |  94 |  120 |  130 |  140 | 200 |\n",
    "| chol      |   303 |  246.6930 |  51.7769  | 126 |  211 |  241 |  275 | 564 |\n",
    "| fbs       |   303 |    0.1485 |   0.3562  |   0 |    0 |    0 |    0 |   1 |\n",
    "| restecg   |   303 |    0.9901 |   0.9950  |   0 |    0 |    1 |    2 |   2 |\n",
    "| thalach   |   303 |  149.6070 |  22.8750  |  71 | 133.5|  153 |  166 | 202 |\n",
    "| exang     |   303 |    0.3267 |   0.4698  |   0 |    0 |    0 |    1 |   1 |\n",
    "| oldpeak   |   303 |    1.0396 |   1.1611  |   0 |    0 |  0.8 |  1.6 | 6.2 |\n",
    "| slope     |   303 |    1.6007 |   0.6162  |   1 |    1 |    2 |    2 |   3 |\n",
    "| ca        |   299 |    0.6722 |   0.9374  |   0 |    0 |    0 |    1 |   3 |\n",
    "| thal      |   301 |    4.7342 |   1.9397  |   3 |    3 |    3 |    7 |   7 |\n",
    "| target    |   303 |    0.9373 |   1.2285  |   0 |    0 |    0 |    2 |   4 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac84d2c0-ef74-464e-939d-8b7d322c2842",
   "metadata": {},
   "source": [
    "Most categorical predictors (cp, fbs, restecg, exang, slope, ca, thal) cover multiple categories, with only minimal missingness in ca and thal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe15ea-5308-4de5-810b-7d1c6c3356b6",
   "metadata": {},
   "source": [
    "| #  | Column    | Non-Null Count | Dtype    |\n",
    "|----|-----------|----------------|----------|\n",
    "| 0  | age       | 303            | int64    |\n",
    "| 1  | sex       | 303            | int64    |\n",
    "| 2  | cp        | 303            | int64    |\n",
    "| 3  | trestbps  | 303            | int64    |\n",
    "| 4  | chol      | 303            | int64    |\n",
    "| 5  | fbs       | 303            | int64    |\n",
    "| 6  | restecg   | 303            | int64    |\n",
    "| 7  | thalach   | 303            | int64    |\n",
    "| 8  | exang     | 303            | int64    |\n",
    "| 9  | oldpeak   | 303            | float64  |\n",
    "| 10 | slope     | 303            | int64    |\n",
    "| 11 | ca        | 299            | float64  |\n",
    "| 12 | thal      | 301            | float64  |\n",
    "| 13 | target    | 303            | int64    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0b887-f7ec-430e-bc2b-ec224edaa5ba",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881e095-cbb9-4dca-8ef6-ae0b0598bce1",
   "metadata": {},
   "source": [
    "The study cohort consisted of 297 individuals, with a slightly higher proportion classified as healthy (160 cases, 53.9%) compared with those with disease (137 cases, 46.1%). Thus, the sample is nearly evenly split between conditions, providing a balanced basis for comparing outcomes between healthy and diseased groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2eed2362-cf3f-48f3-a350-ad95bfea8eae",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/proportion-of-outcomes.png\" alt=\"Proportion of outcomes\" width=\"1000\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 1: Proportion of outcomes</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6ea63-80f1-4c51-9ae4-167667715765",
   "metadata": {},
   "source": [
    "Stratification by gender showed a marked imbalance in disease burden. Among males, the number of disease cases exceeded healthy cases (approximately 110 vs. 90), indicating that disease is the predominant condition in this subgroup. In contrast, females were more often healthy than diseased (around 70 vs. 25 cases), suggesting a lower disease prevalence in women compared with men."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccc7c2b-034a-4e9a-8cf1-ae6dd6183faa",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/proportion-of-disease-by-gender.png\" alt=\"Proportion of disease by gender\" width=\"700\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 2: Proportion of disease by gender</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6e675-b75c-4637-98e5-d408796eca0a",
   "metadata": {},
   "source": [
    "Age-specific analysis indicates that disease is rare in the youngest participants (20-30 years) and remains less frequent than healthy status up to 50 years. From 50-60 years onward, the pattern reverses: disease cases slightly exceed healthy cases in the 50-60 group and remain relatively high in the 60-70 group, suggesting a shift in risk around midlife. In the oldest group (70-80 years) both healthy and diseased counts are low, indicating fewer individuals in this age range rather than a clear difference in disease prevalence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54057621-62c6-41e1-8120-2cd7cbb6cb99",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/disease-occurences-by-age-group.png\" alt=\"Disease occurences by age group\" width=\"700\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 3: Disease occurences by age group</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e291969-edd3-452c-b8b0-390cb64ded32",
   "metadata": {},
   "source": [
    "In the univariate stage, we next examined the marginal distributions of all predictors (Figure 4). Continuous variables such as age, resting blood pressure (trestbps), cholesterol (chol), and maximum heart rate (thalach) are approximately bell-shaped, centered around mid-50s for age, ~130 mmHg for trestbps, ~250 mg/dL for chol, and ~150 bpm for thalach, with a few high-value outliers for chol and oldpeak. ST depression at peak exercise (oldpeak) and the number of major vessels (ca) are clearly right-skewed, with many patients showing no or minimal abnormalities and a small subset with markedly elevated values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9068971-14ca-488c-b3bf-fb656a33b704",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/distributions.png\" alt=\"Distributions of predictors\" width=\"1200\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 4: Distributions of predictors</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f932ca3-3c8b-4fc6-9959-c92b2f5688e6",
   "metadata": {},
   "source": [
    "To further characterize the continuous variables, we inspected them for outliers using boxplots. Oldpeak shows a pronounced right tail, with several observations above 4-6 units, consistent with the strong right-skew seen in its histogram. For age and resting blood pressure, the spread is relatively compact with only a few high values, whereas cholesterol exhibits multiple high outliers, including one very extreme measurement. Maximum heart rate (thalach) also contains a small number of unusually low or high values compared with the bulk of the data.\n",
    "\n",
    "All of these extreme values remain within clinically plausible ranges and likely reflect true high-risk patients rather than data errors. Therefore, they were retained in the dataset, but their presence is important to keep in mind when fitting models and interpreting coefficients, particularly for chol, oldpeak, and thalach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c0c58-2d9f-4f11-8f8c-d6c08ce943f9",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/outliers.png\" alt=\"Outliers\" width=\"900\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 5: Outliers</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5159661-edbd-4007-bb92-5e75730056e6",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/oldpeak.png\" alt=\"Oldpeak skeweness\" width=\"900\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 6: Oldpeak skeweness</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4836b15-12ff-433f-b720-fcbe0b6140b6",
   "metadata": {},
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d94a84d-cb34-4962-9c8a-96c4d32a3f9b",
   "metadata": {},
   "source": [
    "In the multivariate step, we examined the correlation structure among all variables (Figure 7). Overall, correlations between predictors are moderate, suggesting limited multicollinearity. Exercise-related variables form a clear cluster: maximum heart rate (thalach) is inversely correlated with age, while ST depression (oldpeak), ST slope (slope), and exercise-induced angina (exang) are positively interrelated, reflecting a common ischemia/effort tolerance dimension.\n",
    "\n",
    "For the subsequent hypothesis testing, we focus in particular on age, the number of affected vessels (ca), and the disease outcome (target). Age shows a moderate positive correlation with ca (r ≈ 0.36), indicating that older patients tend to have more obstructed vessels. Both variables are also positively correlated with target (r ≈ 0.23 for age-target and r ≈ 0.46 for ca-target), with ca displaying one of the strongest associations with disease in the dataset. This pattern suggests that structural coronary damage (captured by ca) increases with age and is closely linked to the presence of disease. In the next section, we formally test these relationships by comparing age distributions across outcome groups and assessing the association between ca and target using Chi$^2$ test for independence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d1719-dea9-4277-bb23-35dc99b24224",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/corr.png\" alt=\"Correlation between variables\" width=\"1200\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 7: Correlation between variables</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643349b-ffde-449b-ba7e-a1d237404220",
   "metadata": {},
   "source": [
    "The contingency heatmap of heart disease status by number of major vessels (ca) shows a clear monotonic pattern. Among patients with no visible major vessel involvement (ca = 0), the majority are disease-free (129 without vs. 45 with disease). As the number of affected vessels increases, this relationship reverses: for ca = 1, counts of diseased and non-diseased patients are roughly similar (44 vs. 21), while for ca = 2 and ca = 3, diseased patients clearly dominate (31 vs. 7 and 17 vs. 3, respectively).\n",
    "\n",
    "These frequencies suggest that higher vessel involvement is strongly associated with the presence of heart disease, consistent with the relatively high positive correlation between ca and the target variable observed in the correlation matrix. In the following hypothesis testing section, we formally assess this association using a test for independence between ca and disease outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137a11d-aaed-455a-8417-c900d56e490f",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/major-vessels-heart-disease.png\" alt=\"Observed implication of major vessels visibility on heart disease\" width=\"600\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 8: Observed implication of major vessels visibility on heart disease</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14cb3c-b73b-4ce3-82ac-e6a826f88655",
   "metadata": {},
   "source": [
    "---\n",
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7414021e-c08b-482e-8765-b8db65efec91",
   "metadata": {},
   "source": [
    "Motivated by the strong positive correlation between the number of major vessels (ca) and disease status, and the clear pattern in the contingency heatmap, we formally tested whether ca and heart disease are statistically associated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7652201-f422-4769-a2ef-7665dbf769af",
   "metadata": {},
   "source": [
    "Both variables are categorical (ca: 0-3 vessels; disease: present/absent), so we use a chi-square test of independence on their contingency table.\n",
    "- Null hypothesis $H_0$: Number of major vessels on imaging and heart disease outcome are independent.\n",
    "- Alternative hypothesis $H_A$: Number of major vessels on imaging and heart disease outcome are NOT independent (are associated)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f10161-c1a6-4552-8a38-fc5d23497dbb",
   "metadata": {},
   "source": [
    "Observed contingency table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812d338-b997-4c7e-99df-996a57e709ca",
   "metadata": {},
   "source": [
    "| Number of major vessels (ca) | No heart disease | Heart disease | Row total |\n",
    "| ---------------------------- | ---------------- | ------------- | --------- |\n",
    "| 0                            | 129              | 45            | 174       |\n",
    "| 1                            | 21               | 44            | 65        |\n",
    "| 2                            | 7                | 31            | 38        |\n",
    "| 3                            | 3                | 17            | 20        |\n",
    "| **Column total**             | **160**          | **137**       | **297**   |\n",
    "\n",
    "<center><i>Table 2: Contigency table of observed values.</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e0e2b-9c68-4a53-99f8-d6e7ce3d765c",
   "metadata": {},
   "source": [
    "Expected counts are computed from row and column totals as $$E_{ij} = \\frac{(row\\ total_i)(column\\ total_j​)}{N}$$ \\\n",
    "where $N = 297$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7787b-d690-44e2-aa10-c89ea4c263e2",
   "metadata": {},
   "source": [
    "For example, for $ca = 0$ and “No heart disease”: $$E_{11} = \\frac{174 * 160}{297} \\approx 93.74$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdccdcc-788b-4974-a72c-86246323ecbb",
   "metadata": {},
   "source": [
    "The full table of expected frequencies is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22120c3c-5f8b-493b-b0c1-66439fe9c792",
   "metadata": {},
   "source": [
    "| Number of major vessels (ca) | No heart disease (E) | Heart disease (E) | Row total |\n",
    "| ---------------------------- | -------------------- | ----------------- | --------- |\n",
    "| 0                            | 93.74                | 80.26             | 174       |\n",
    "| 1                            | 35.02                | 29.98             | 65        |\n",
    "| 2                            | 20.47                | 17.53             | 38        |\n",
    "| 3                            | 10.77                | 9.23              | 20        |\n",
    "| **Column total**             | **160.00**           | **137.00**        | **297**   |\n",
    "\n",
    "<center><i>Table 3: Contigency table of expected values.</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d8b272-1663-4d1c-8168-19365803c6a7",
   "metadata": {},
   "source": [
    "The chi-square test statistic is $$\\chi^2 = \\sum_{i=1}^4\\sum_{j=1}^2{\\frac{(O_{ij} - E_{ij})^2}{E_{ij}}}$$\n",
    "where $O_{ij}$ and $E_{ij}$ are the observed and expected counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e6a15-05a9-4604-9ff7-3632805a1ad6",
   "metadata": {},
   "source": [
    "For example, the contribution from the cell ($ca = 0$, no disease) is $$\\frac{(129 - 93.74)^2}{93.74} \\approx 13.27$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39dca58-13d2-4b05-bb6d-05b83ec35016",
   "metadata": {},
   "source": [
    "Summing the contributions from all 8 cells gives $$\\chi^2 \\approx 72.30$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a2a29-0319-4b68-8995-8e096cda0643",
   "metadata": {},
   "source": [
    "The degrees of freedom are $$df = (r - 1)(c - 1) = (4 - 1)(2 - 1) = 3$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79998fb-26ac-4dc6-abf4-185a24927536",
   "metadata": {},
   "source": [
    "and the corresponding p-value is $$p \\approx 1.37 * 10^{-15}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fd072-dccd-49e8-a212-8036baae92d5",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eee901-76f0-4294-9c6d-5cda263377bd",
   "metadata": {},
   "source": [
    "With $\\chi^2 \\approx 72.30, df = 3$, and an extremely small p-value, we reject $H_0$ at any conventional significance level. There is very strong evidence that the number of major vessels (ca) and heart disease status are not independent: patients with more affected vessels are much more likely to have heart disease. This result supports the earlier descriptive findings and justifies using ca as a key predictor in subsequent modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad809ea0-a387-498b-98b5-d5a172f85ca3",
   "metadata": {},
   "source": [
    "---\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad86adb-12ba-4703-ae70-8932b155bd59",
   "metadata": {},
   "source": [
    "For the modeling stage, we first separated predictors and outcome by defining the feature matrix $X$ as all variables except target, and the response vector $y$ as the binary heart disease indicator. The data was then split into training and test sets using a stratified train-test split with 70% of observations used for training and 30% for testing. Stratification on $y$ ensures that the proportion of diseased and non-diseased patients is preserved in both subsets, which is important for obtaining an unbiased estimate of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6558a-853c-43dd-91b5-03363b2f29a3",
   "metadata": {},
   "source": [
    "Next, we constructed a preprocessing pipeline based on the variable types. Numerical predictors were identified using their integer/float data types, and categorical predictors were identified using `category` and boolean types. A `ColumnTransformer` was then used to apply different transformations to these two groups:\n",
    "- **Numerical features** were scaled with RobustScaler, which centers variables using the median and rescales them based on the interquartile range. This approach reduces the influence of extreme values and skewed distributions on the model, making the inputs more stable for algorithms that estimate class-conditional densities, such as Gaussian Naive Bayes.\n",
    "- **Categorical features** were encoded using `OneHotEncoder` with `sparse_output=False` to produce a dense design matrix. This is necessary because the Gaussian Naive Bayes implementation in scikit-learn expects dense input and cannot directly work with sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b01fb-f3c0-4d83-a1e3-ff634bf2be5a",
   "metadata": {},
   "source": [
    "All remaining columns were dropped (`remainder='drop'`), so only the explicitly specified numerical and categorical predictors enter the model. This preprocessing pipeline is later combined with the classifier in a single workflow, ensuring that the same transformations are consistently applied during both training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e48646-4e59-4a3b-bae0-b5ff3967df15",
   "metadata": {},
   "source": [
    "> For complete preprocessing step, please, see [implementation notebook](https://github.com/vregi/heart-disease-classification/blob/main/implementation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d61803-133a-4454-8d34-7e833ab4b91e",
   "metadata": {},
   "source": [
    "For the classification task, we compared two simple but commonly used baseline models: Logistic Regression and Gaussian Naive Bayes. Logistic Regression was configured with an increased maximum number of iterations (`max_iter` = 1000) to ensure convergence, while Gaussian Naive Bayes was used with its default probabilistic formulation. Both models were wrapped inside a single `Pipeline` together with the previously defined preprocessing step, so that scaling and encoding are applied consistently during training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52776df8-f32d-436b-88e1-b8ef3d6a0352",
   "metadata": {},
   "source": [
    "Each model was trained on the same stratified training set $(X_{train}, y_{train})$, and evaluated on the held-out test set $(X_{test}, y_{test})$. After fitting, we obtained class predictions $\\hat{y}$ using `predict` and estimated class probabilities using `predict_proba`, from which we extracted the probability of heart disease (positive class). Model performance was quantified using several standard metrics: overall accuracy on the test set, the **ROC-AUC** computed from the predicted probabilities (to assess discrimination across all possible thresholds), and the **confusion matrix**, which summarizes true positives, true negatives, false positives, and false negatives. For each model, all relevant objects (fitted pipeline, predictions, scores, confusion matrix, and metrics) were stored for subsequent comparison and visualization in the results section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f810ad8-3414-4785-9645-786c7e99eb77",
   "metadata": {},
   "source": [
    "> For complete modeling step, please, see [implementation notebook](https://github.com/vregi/heart-disease-classification/blob/main/implementation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b816dbb-e7a5-4c57-b806-d911efa151fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6249e62d-62ec-489b-822e-dc3fc48c0336",
   "metadata": {},
   "source": [
    "After training both logistic regression and Gaussian Naive Bayes on the processed dataset, we assessed their performance on a held-out test set using threshold-dependent and threshold-independent metrics. In particular, we report overall accuracy and ROC-AUC to quantify global discrimination, and precision, recall, and F1-scores separately for the disease and no-disease classes to capture the trade-off between correctly detecting heart disease and avoiding false alarms. \n",
    "\n",
    "This section summarizes and compares these results and discusses their practical implications in a screening context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf95ad8-9f3e-42da-a6d0-4a043729c9e9",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbee68-f251-44eb-b299-18de474db899",
   "metadata": {},
   "source": [
    "On the held-out test set, both models achieved strong predictive performance. \n",
    "\n",
    "The Gaussian Naive Bayes classifier reached an accuracy of about **0.83** with a ROC-AUC above **0.93**, indicating very good separation between diseased and non-diseased patients; it showed high precision for the disease class and particularly strong recall for the no-disease class, meaning it correctly identified most healthy individuals but still missed a fraction of true positives. \n",
    "\n",
    "The logistic regression model obtained a slightly higher overall accuracy (around **0.86**) and ROC-AUC close to **0.95**, with very high recall for the no-disease class and excellent precision for the disease class, reflecting reliable positive predictions but again some missed cases. Overall, both approaches deliver clinically useful discrimination on this dataset, with a trade-off between correctly ruling out healthy patients and capturing all true disease cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643c9c0-6b01-402b-bd7c-fe88644e1b3b",
   "metadata": {},
   "source": [
    "| Model                | Overall |  | No disease |  |  | Disease |  |  |\n",
    "|----------------------|:-------:|:-------:|:----------:|:----------:|:----------:|:-------:|:-------:|:-------:|\n",
    "|                      | Accuracy| ROC-AUC | Precision  |   Recall   |    F1      | Precision|  Recall |   F1    |\n",
    "| Logistic Regression  | 0.8333  | 0.9325  |   0.81     |   0.90     |   0.85     |  0.86   |  0.76   |  0.81   |\n",
    "| Gaussian Naive Bayes | 0.8556  | 0.9469  |   0.82     |   0.94     |   0.87     |  0.91   |  0.76   |  0.83   |\n",
    "\n",
    "<center><i>Table 4: Metrics table</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64a92a-d831-4dc5-b8d7-04cdab433be2",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba488d6-47bb-4669-b639-1ec44a4c1280",
   "metadata": {},
   "source": [
    "The confusion matrices highlight how the two models trade off different types of errors. \n",
    "\n",
    "For logistic regression, 43 of 48 no-disease cases are correctly classified (5 false positives), and 32 of 42 disease cases are correctly identified (10 false negatives). \n",
    "\n",
    "Gaussian Naive Bayes slightly improves performance on the no-disease class, correctly classifying 45 of 48 healthy patients (3 false positives), while keeping the same number of true positives for disease (32) and thus the same number of false negatives (10). \n",
    "\n",
    "Overall, Naive Bayes is slightly more conservative in predicting disease, reducing false alarms at the cost of not improving sensitivity for true disease cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be9918-d451-4e47-9177-049cc9fcf046",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/confusion_matrices.png\" alt=\"Confusion Matrices\" width=\"1200\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 9: Confusion Matrices</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02bac1-dc76-4a3e-a8ee-4e385f240e83",
   "metadata": {},
   "source": [
    "### ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd25d08e-3466-4363-8c91-7449c872c5ef",
   "metadata": {},
   "source": [
    "The ROC curves show that both models achieve strong discrimination between patients with and without heart disease across a wide range of decision thresholds. \n",
    "\n",
    "The curves for logistic regression and Gaussian Naive Bayes lie well above the diagonal, with areas under the curve of approximately **0.93** and **0.95**, respectively. The Naive Bayes curve is slightly closer to the top-left corner, reflecting a small advantage in simultaneously maintaining high true-positive rates at relatively low false-positive rates. \n",
    "\n",
    "This confirms that, on the test set, both classifiers provide clinically meaningful ranking of risk, with Gaussian Naive Bayes offering marginally better overall ranking performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6f4af-4915-4ac7-93f4-5dd19fa4a253",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"artifacts/roc_curves.png\" alt=\"ROC Curves\" width=\"1200\"/>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><em>Figure 10: ROC Curves</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f13cb-123a-4fb8-8805-901c79ba5fbc",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86896614-650c-45bf-a9b1-446db77c9646",
   "metadata": {},
   "source": [
    "To assess how stable these results are with respect to the particular train-test split, we performed stratified 5-fold cross-validation on the training data for both models. \n",
    "\n",
    "Logistic Regression achieved mean accuracy of about **0.84** (range ≈ 0.75-0.92), whereas Gaussian Naive Bayes reached a lower mean accuracy of about **0.79** (range ≈ 0.70-0.88). \n",
    "\n",
    "Thus, although Naive Bayes appeared slightly better on the single held-out test set, repeated resampling suggests that Logistic Regression is, on average, the more reliable classifier, with better expected performance across different splits of the data. This supports choosing Logistic Regression as the primary model for deployment, while still recognizing Naive Bayes as a competitive and more parsimonious alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f177861-6ca9-4a07-b37f-6d462f0b58ef",
   "metadata": {},
   "source": [
    "| Model                | Fold 1  | Fold 2 | Fold 3 | Fold 4 | Fold 5 | Mean accuracy ± SD |\n",
    "|----------------------|:-------:|:------:|:------:|:------:|:------:|:------------------:|\n",
    "| Logistic Regression  | 0.92    | 0.85   | 0.75   | 0.85   | 0.83   | 0.84 ± 0.06        |\n",
    "| Gaussian Naive Bayes | 0.88    | 0.70   | 0.75   | 0.78   | 0.85   | 0.79 ± 0.07        |\n",
    "\n",
    "<center><i>Table 5: Stratified K-Fold cross-validation results</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717892a-6335-410f-b629-27a61bebdb99",
   "metadata": {},
   "source": [
    "---\n",
    "## Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a29d4c-db09-481e-b16b-661b6d971a04",
   "metadata": {},
   "source": [
    "- #### Dataset and population\n",
    "\n",
    "The dataset includes 303 predominantly middle-aged to older patients (mean age ≈ 54 years), with a clear male majority.\n",
    "\n",
    "Classic cardiovascular risk factors (blood pressure, cholesterol, exercise response) are moderately elevated and show substantial variability, reflecting a clinically heterogeneous cohort.\n",
    "\n",
    "- #### Univariate patterns and risk factors\n",
    "\n",
    "Disease prevalence is slightly below 50% overall, but strongly imbalanced across subgroups.\n",
    "\n",
    "Men and older age groups (≥50 years) show markedly higher disease frequencies than women and younger patients, supporting known epidemiological patterns.\n",
    "\n",
    "Several continuous variables (cholesterol, oldpeak, ca) exhibit right-skew and clinically plausible high outliers; these were retained and handled via robust scaling.\n",
    "\n",
    "- #### Association between vessels (`ca`), age, and disease\n",
    "\n",
    "Age correlates positively with the number of affected vessels (ca), and both are positively associated with disease status.\n",
    "\n",
    "The contingency analysis of ca vs. disease shows a clear monotonic trend: as the number of affected vessels increases from 0 to 3, the proportion of patients with heart disease rises sharply.\n",
    "\n",
    "A chi-square test of independence confirms a strong, statistically significant association between ca and heart disease $(\\chi^2 \\approx 72.3, df = 3, p < 0.001)$, indicating that vessel involvement is a key structural marker of disease in this dataset.\n",
    "\n",
    "- #### Model performance on the test set\n",
    "\n",
    "Both models-Logistic Regression and Gaussian Naive Bayes-achieve good discrimination (ROC-AUC ≈ 0.93-0.95) and high accuracy (≈0.83-0.86) on the held-out test set.\n",
    "\n",
    "Confusion matrices show that both models correctly classify most healthy patients, while missing a smaller but non-negligible fraction of diseased patients.\n",
    "\n",
    "Gaussian Naive Bayes appears slightly better on the single test split (higher accuracy and ROC-AUC, fewer false positives), suggesting that a simple probabilistic model can capture much of the predictive structure in the data.\n",
    "\n",
    "- #### Model robustness and preferred classifier\n",
    "\n",
    "Cross-validation on the training data reveals that Logistic Regression has a higher mean accuracy (≈0.84) and slightly smaller variance across folds than Gaussian Naive Bayes (≈0.79).\n",
    "\n",
    "This indicates that Logistic Regression is more robust to sampling variation and is likely to generalize more consistently to new data, even though Naive Bayes performed marginally better on the specific test split.\n",
    "\n",
    "Overall, Logistic Regression emerges as the preferred model for deployment, with Gaussian Naive Bayes serving as a strong, interpretable baseline that confirms the stability of the main predictive signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f9c8ba-0b20-4d16-b75f-7631d0b30382",
   "metadata": {},
   "source": [
    "---\n",
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b64907-63d5-46b3-bb9d-78692ba2bed9",
   "metadata": {},
   "source": [
    "- #### Limited clinical detail of predictors\n",
    "Several variables are relatively coarse and may not reflect current best practice in cardiovascular risk assessment. For example, chol represents total cholesterol, whereas treatment decisions usually rely on **LDL** cholesterol (and its ratio to HDL) rather than on a single aggregate value. High HDL can “mask” high **LDL** in the total cholesterol measure, so important risk may be underestimated. Similar simplifications likely apply to other predictors (e.g. binary fasting blood sugar, simplified exercise-ECG categories), which can blunt the true signal and limit the clinical interpretability of the models.\n",
    "\n",
    "- #### Restricted dataset and potential bias\n",
    "The analysis is based on a single, relatively small dataset (303 patients) with a male-dominated, middle-aged population. This restricts the ability to generalize the findings to other settings, age groups, or contemporary patients with different prevalence of risk factors and treatment patterns. No external validation was performed, so the reported performance may be optimistic.\n",
    "\n",
    "- #### Simplifying modeling assumptions\n",
    "The Gaussian Naive Bayes model assumes conditional independence between predictors and (after scaling) approximately Gaussian distributions within each class-assumptions that are clearly only approximate here. Even logistic regression is linear in the log-odds and may miss more complex, non-linear interactions between features (e.g. age × exercise response, multi-factor metabolic risk).\n",
    "\n",
    "- #### Scope of methods and role of ML in practice\n",
    "We deliberately focused on simple, transparent statistical models. While their performance is encouraging, more modern approaches (e.g. gradient boosting, random forests, or neural networks) could potentially capture richer patterns and further improve discrimination, especially in larger datasets. At the same time, ML systems-particularly those trained on limited and simplified data-should not be used as autonomous decision-makers in a complex domain like cardiology. Their appropriate role is to support clinicians by highlighting patterns and estimating risk, while final diagnostic and treatment decisions remain grounded in expert clinical judgment and patient-specific context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5763ddb9-58e1-4885-84ff-fd6a0ae9057e",
   "metadata": {},
   "source": [
    "---\n",
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5123c100-3b54-4539-a1e6-5e5a513cb555",
   "metadata": {},
   "source": [
    "- #### Richer and more granular clinical variables\n",
    "A natural next step is to extend the feature set with more clinically specific biomarkers (e.g. LDL, HDL, triglycerides, HbA1c), medication use, and imaging-derived measures. This would address some of the limitations of total cholesterol and other coarse predictors, and allow the models to better reflect contemporary cardiology practice.\n",
    "\n",
    "- #### Larger and more diverse datasets\n",
    "Training and validating the models on larger, multi-center cohorts would improve statistical power, allow more reliable subgroup analyses (e.g. by sex, age, comorbidity profile), and test generalizability across different populations and healthcare settings. External validation on an independent dataset should be a priority.\n",
    "\n",
    "- #### Expanded modeling and tuning\n",
    "Beyond Gaussian Naive Bayes and logistic regression, future work could explore tree-based ensembles (Random Forests, Gradient Boosting, XGBoost), regularized models, and calibrated probabilistic methods. Systematic hyperparameter tuning and model selection, guided by cross-validation and calibration metrics, may yield more accurate and better-calibrated risk predictions.\n",
    "\n",
    "- #### Model interpretability and clinical integration\n",
    "Applying model-agnostic explanation methods (e.g. partial dependence plots, SHAP values) could clarify how each feature contributes to predicted risk and help clinicians understand when to trust or question model outputs. Translating risk scores into clinically meaningful thresholds and decision rules (e.g. via decision-curve analysis) would be a key step toward practical use.\n",
    "\n",
    "- #### Prospective and workflow-oriented evaluation\n",
    "Ultimately, the most informative evaluation would involve prospective testing in routine clinical workflows, examining not only predictive performance but also effects on clinician behavior, time to diagnosis, and patient outcomes. Any such deployment should be explicitly framed as decision support, complementing rather than replacing clinician judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d62e86-dab3-4b9a-9dae-d7d7f17cca30",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea698954-fa46-4db9-8176-1e61b6a61aa2",
   "metadata": {},
   "source": [
    "In summary, we showed that even simple, transparent models can extract clinically meaningful patterns from routine heart disease data. Exploratory analysis confirmed known risk gradients by age, sex, and vessel involvement, and hypothesis testing highlighted the strong association between the number of affected vessels and disease status. \n",
    "\n",
    "Both Gaussian Naive Bayes and logistic regression achieved good discrimination on the test set, with logistic regression emerging as the more robust choice overall. While these results are encouraging, they are based on limited and somewhat simplified data, and the models should be viewed as decision-support tools rather than replacements for clinical expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e6fdb-a4dd-4361-8726-1e3203f6b82b",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a2f9b-e7ef-46e4-ac4a-dceeb69901cc",
   "metadata": {},
   "source": [
    "### A. Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fe15e-d81a-4c66-a8e2-247e4a968d04",
   "metadata": {},
   "source": [
    "All data preparation, analysis, and visualization were performed using separate Jupyter notebook. Each step described in the report corresponds directly to it's structure. This notebook contain the full implementation and can be accessed using the link below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b6af63-9d65-4940-aafd-1a232c231bfa",
   "metadata": {},
   "source": [
    "Implementation Notebook - https://github.com/vregi/heart-disease-classification/blob/main/implementation.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c68bb6e-3473-43c9-85bd-2023602e351f",
   "metadata": {},
   "source": [
    "### B. Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca2187-f445-4e49-ae5e-03fcc1897194",
   "metadata": {},
   "source": [
    "The data used in this project come from the Heart Disease dataset hosted at the UC Irvine Machine Learning Repository. It is a widely used benchmark dataset derived from clinical records (primarily the Cleveland Clinic subset) and contains demographic, clinical, and exercise test variables together with a labeled heart disease outcome. The dataset was obtained in its processed tabular form and used without modification apart from the preprocessing steps described in the main text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e945a3e-dd71-44f7-89ea-52e63fa33a58",
   "metadata": {},
   "source": [
    "Data Source - https://archive.ics.uci.edu/dataset/45/heart+disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7869f-ec1b-48ac-8db3-47949d4428f2",
   "metadata": {},
   "source": [
    "### C. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582eaeb-997a-4e19-a07f-a201029e4276",
   "metadata": {},
   "source": [
    "[1] : World Health Organization. Cardiovascular diseases (CVDs): Fact sheet. Available at: https://www.who.int/news-room/fact-sheets/detail/cardiovascular-diseases-(cvds) \\\n",
    "[2] : Banerjee, T. et al. A systematic review of machine learning in heart disease prediction. Available at: https://pmc.ncbi.nlm.nih.gov/articles/PMC12614364/ \\\n",
    "[3] : scikit-learn developers. 1.9. Naive Bayes - scikit-learn User Guide. Available at: https://scikit-learn.org/stable/modules/naive_bayes.html \\\n",
    "[4] : Bishop, C. M. Pattern Recognition and Machine Learning. Chapter 4, p.205-206 Springer, 2006. PDF version available at: https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7710c85e-2097-4eb2-9051-d7e4c4827062",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right; margin-top: 40px;\">\n",
    "<strong>Vladyslav Lysenko</strong> &nbsp;&nbsp; <strong>Parmida Mashadi Assadollahi</strong> &nbsp;&nbsp; <strong>Sankruththian Senathirajah</strong><br>\n",
    "University of Toronto School of Continuing Studies<br>\n",
    "August 2025\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
